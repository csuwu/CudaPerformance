\documentclass[12pt, a4paper]{article}
\usepackage{tikz}
\usepackage{datetime}
\usepackage{pgfplots}
\usepackage{array}
\usepackage{tabu}
\usepackage{tocloft}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\usepackage{geometry}

 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
 }


\font\titlefont=cmr12 at 40pt
\font\metafont=cmr12 at 14pt

\title{\titlefont{Matrix Multiplication Runtime}}
\author{M.A.S SURANGA (CST140043)}
\date{}

\begin{document}

	\maketitle

	\vspace*{5\baselineskip} 
	\begin{center}
	\metafont{Generated on \today \ \currenttime}
	\end{center}

	\newpage
	\setlength{\cftbeforesecskip}{6pt}
	\tableofcontents

	\newpage
	\section{Introduction}
	\hfill \break

	\textbf{Report Content}

	\hfill \break

	This report compares the performance of matrix multiplication on CPU and Nvidia GPU. CPU program uses the naive approach for computation and GPU programs contain two parallel source codes that uses global memory and shared memory.  

	\hfill \break

	\textbf{Testcases Details}

	\hfill \break


	\begin{tabu} to 1 \textwidth { | X[l] | X[r] | }
		 \hline
		 Matrix Sizes & \input{meta_sizes.dat}  \\
		 \hline
		 Block Size(Threads Per Block) & \input{meta_block.dat}  \\
		 \hline
		 No. of iterations & \input{meta_avg.dat}  \\
		 \hline
		 Fixed Matrix Size & \input{meta_fixedmatrix.dat}  \\
		 \hline
		 Fixed Block Size & \input{meta_fixedblock.dat}  \\ 
		 \hline
	\end{tabu}	
	

	\newpage

	\section{CPU Program runtime}

	\par
	This program is executed in normal CPU and $x,y$ values are extracted from the average runtime of each different matrix sizes.
	\hfill \break

	\begin{tikzpicture}
		\begin{axis}[grid=major, grid style={black!20}, width=\linewidth, xlabel=Matrix size,ylabel=Runtime(secs.),legend style={at={(0,-0.3)},anchor=south}]
			\addplot[color=red,mark=x] table[ignore chars={(,)},col sep=comma] {datafile0.dat};
			\addlegendentry{$CPU$}
		\end{axis}
	\end{tikzpicture}

	\newpage

	\section{GPU Global Memory Program(CUDA) runtime}

	\par
	This program is executed in Nvdia GPU (Global memory used) and $x,y$ values are extracted from the average runtime of each different matrix sizes.
	\hfill \break

	\begin{tikzpicture}
		\begin{axis}[grid=major, grid style={black!20}, width=\linewidth, xlabel=Matrix size,ylabel=Runtime(secs.),legend style={at={(0,-0.3)},anchor=south}]
			\addplot[color=green,mark=x] table[ignore chars={(,)},col sep=comma] {datafile1.dat};
			\addlegendentry{$GPU (Global)$}
		\end{axis}
	\end{tikzpicture}

	\newpage

	\section{GPU Shared Memory Program(CUDA) runtime}

	\par
	This program is executed in Nvidia GPU(Shared memory) and $x,y$ values are extracted from the average runtime of each different matrix sizes.
	\hfill \break

	\begin{tikzpicture}
		\begin{axis}[grid=major, grid style={black!20}, width=\linewidth, xlabel=Matrix size,ylabel=Runtime(secs.),legend style={at={(0,-0.3)},anchor=south}]
			\addplot[color=blue,mark=x] table[ignore chars={(,)},col sep=comma] {datafile2.dat};
			\addlegendentry{$GPU (Shared)$}
		\end{axis}
	\end{tikzpicture}

	\newpage

	\section{CPU vs GPU Performance Comparison}

	\par
	Previous plots are compared within same graph. According to the plots it is clear that GPU execution is giving very good performance than the CPU.  
	\hfill \break

	\begin{tikzpicture}
		\begin{axis}[grid=major, grid style={black!20}, width=\linewidth, xlabel=Matrix size,ylabel=Runtime(secs.),legend style={at={(0,-0.3)},anchor=south}]
			\addplot[color=red,mark=x] table[ignore chars={(,)},col sep=comma] {datafile0.dat};
			\addlegendentry{$CPU$}
			\addplot[color=green,mark=x] table[ignore chars={(,)},col sep=comma] {datafile1.dat};
			\addlegendentry{$GPU (Global)$}
			\addplot[color=blue,mark=x] table[ignore chars={(,)},col sep=comma] {datafile2.dat};
			\addlegendentry{$GPU (Shared)$}
		\end{axis}
	\end{tikzpicture}

	\newpage

	\section{Shared Memory vs Global memory of GPU}

	This graph compares the efficiency between shared memory and global memory of the Nvidia GPU. According to the graph the Shared memory program gives good performance comparing to Global memory program. 
	\hfill \break

	\begin{tikzpicture}
		\begin{axis}[grid=major, grid style={black!20}, width=\linewidth, xlabel=Matrix size,ylabel=Runtime(secs.),legend style={at={(0,-0.3)},anchor=south}]
			\addplot[color=green,mark=x] table[ignore chars={(,)},col sep=comma] {datafile1.dat};
			\addlegendentry{$GPU (Global)$}
			\addplot[color=blue,mark=x] table[ignore chars={(,)},col sep=comma] {datafile2.dat};
			\addlegendentry{$GPU (Shared)$}
		\end{axis}
	\end{tikzpicture}

	\newpage

	\par
	This graph compares the efficiency between shared memory and global memory of GPU with block size(threads per block).
	\\
	\\
	Fixed Matrix size - \input{meta_fixedmatrix.dat}x\input{meta_fixedmatrix.dat} 
	\hfill \break

	\begin{tikzpicture}
		\begin{axis}[grid=major, grid style={black!20}, width=\linewidth, xlabel=Threads Per Block,ylabel=Runtime(secs.),legend style={at={(0,-0.3)},anchor=south}]
			\addplot[color=green,mark=x] table[ignore chars={(,)},col sep=comma] {datafile3.dat};
			\addlegendentry{$GPU (Global)$}
			\addplot[color=blue,mark=x] table[ignore chars={(,)},col sep=comma] {datafile4.dat};
			\addlegendentry{$GPU (Shared)$}
		\end{axis}
	\end{tikzpicture}

	\newpage
	\section{Conclusion}

	\begin{itemize}
		\item Using first graphs it is clear that GPU execution of matrix multiplication program is giving very good performance. Thus CPU execution gives a plot similar to cubic curve since we used naive $O(n^3)$ algorithm here. Further CPU program can be optimized using several algorithms(Eg :- Solvay Strassen Algorithm).

		\item Shared memory decreases the execution time of the program because shared memory is onchip memory unlike global memory. 

		\item In conclusion Shared memory approach is the most efficient method for matrix multiplication computation among all program types.

		\item Thus If the Block size is being increased in shared memory approach there is apparent performance gain.
	\end{itemize}

	\hfill \break
	Following table compares the efficiency of matrix muliplication for \\ \input{meta_tablematrixsize.dat}x\input{meta_tablematrixsize.dat} matrix.
	\hfill \break

	\begin{tabu} to 1 \textwidth { | X[l] | X[r] | }
		 \hline
		 \textbf{Approach} & \textbf{Time(secs.)}  \\
		 \hline
		 CPU & \input{meta_tablematrix_1.dat}  \\
		 \hline
		 GPU (Global Memory) & \input{meta_tablematrix_2.dat}  \\
		 \hline
		 GPU (Shared Memory) & \input{meta_tablematrix_3.dat}  \\
		 \hline
	\end{tabu}		

	\newpage


	\section{References}

	\begin{itemize}
	  \item https://www.tug.org/twg/mactex/tutorials/ltxprimer-1.0.pdf.
	  \item https://gist.github.com/LeCoupa/122b12050f5fb267e75f
	  \item https://tex.stackexchange.com/questions
	\end{itemize}

\end{document}

